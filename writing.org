#+HUGO_BASE_DIR: ./
#+HUGO_SECTION: ./
#+TITLE: Source for Hugo

* Introduction

The only way to learn something properly is to paraphrase the understanding.
This file is a compilation of my effort on understanding interesting concepts.

Every heading can be considered a post, depending on the properties it is either
exported as a valid post or remains an information in this file.

=ox-hugo= is used for exporting this file as a proper hugo source.

* Deployment

Hugo theme: https://github.com/jakewies/hugo-theme-codex

Add theme:
#+BEGIN_SRC sh :results silent
  git clone https://github.com/jakewies/hugo-theme-codex.git themes/hugo-theme-codex
#+END_SRC

** Code blocks to be run for deployment

   #+NAME: clean-env
   #+BEGIN_SRC sh :results silent
     #!/bin/sh
     rm -rf docs
     rm -rf public
     rm -rf content
   #+END_SRC

   #+NAME: create-src
   #+BEGIN_SRC elisp :results silent
     (org-hugo-export-wim-to-md t)
   #+END_SRC

   #+NAME: create-site
   #+BEGIN_SRC sh :results silent
     #!/bin/sh
     hugo
   #+END_SRC

   #+NAME: deploy
   #+BEGIN_SRC sh :results silent
     #!/bin/sh
     mv public docs
     git add writing.org docs/.
     git commit -m "Updated source of truth and regenerated files"
     git push origin master
   #+END_SRC

** Running the code blocks in order

   This is the actual deployment script. =switch= anologous to what
   =home-manager switch= does.

   #+NAME: switch
   #+BEGIN_SRC elisp :results silent
     (org-sbe clean-env)
     (org-sbe create-src)
     (org-sbe create-site)
     (org-sbe deploy)
    #+END_SRC

* Index
  :PROPERTIES:
  :EXPORT_FILE_NAME: _index
  :EXPORT_HUGO_MENU: :menu "main"
  :EXPORT_HUGO_CUSTOM_FRONT_MATTER: :heading "Hi, I'm Adithya" :subheading "Food + Functional programming" :handle "adithyaov"
  :END:

* Writing
  :PROPERTIES:
  :EXPORT_FILE_NAME: _index
  :EXPORT_HUGO_SECTION: blog
  :EXPORT_HUGO_MENU: :menu "main"
  :END:

* DONE From folds to parsers                                       :streamly:
  :PROPERTIES:
  :EXPORT_FILE_NAME: folds-to-parsers
  :EXPORT_HUGO_SECTION: blog
  :EXPORT_DATE: 2021-01-30
  :END:

  #+BEGIN_EXPORT html
  <style>
    .language-haskell {
      color: #fff!important;
    }
    .builtin {
      color: #fff!important;
    }
    .string {
      color: #fff!important;
    }
  </style>
  #+END_EXPORT

** Introduction

   Folds are fundamental building blocks of functional programming. Every main
   function can more-or-less be represented by a fold.

   In this article we'll see how parsers are a simple extension to folds. We'll
   start with =foldl= and evolve it into a parser.

** Design

   Consider the type of a =foldl=,

   #+BEGIN_SRC haskell
     foldl :: (s -> a -> s) -> s -> [a] -> b
   #+END_SRC

   We can represent this as a data type,

   #+BEGIN_SRC haskell
     -- | Data type representing the fold
     data Fold a b =
         forall s. Fold (s -> a -> s) s (s -> b)

     -- | The fold driver that runs the fold
     driver :: Fold a b -> [a] -> b
     driver (Fold step initial extract) stream = go initial stream

         where

         go s [] = extract s
         go s (a:xs) = go (step s a) xs
   #+END_SRC

   For the ease of representation and combination we keep the state of the fold
   internal. Instead, we add a function =(s -> b)= to extract this internal
   state.

   Additional to the process of folding, the parser has these properties,
   - termination
   - backtracking
   - error handeling

   From the parser type, the parser driver should know whether to terminate, the
   amount to backtrack and whether the parse is a success or a failure.

   Extending for termination,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial s
         | Done b

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b

     -- | Data type representing the fold
     data Fold2 a b =
         forall s. Fold2 (s -> a -> Step s b) (Initial s b) (s -> b)

     -- | The fold driver that runs the fold
     driver :: Fold2 a b -> [a] -> b
     driver = error "Try implementing this yourself"
   #+END_SRC

   =Fold2= represents terminating folds. The driver can terminate when it
   encounters =IDone= or =Done=. The implementation of the driver is left to the
   reader.

   The reason we have different types for representing the result of step &
   initial is beause I preemptively know that these types are going to
   diverge. If you just want to create terminating folds you can use the same
   data type.

   Extending for error handeling,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial s
         | Done b
         | Error String

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b
         | IError String

     -- | This is the result of @extract@
     type Extract b = Either String b

     -- | Data type representing the fold
     data Fold3 a b =
         forall s. Fold3 (s -> a -> Step s b) (Initial s b) (s -> Extract b)

     -- | The fold driver that runs the fold
     driver :: Fold3 a b -> [a] -> b
     driver = error "Try implementing this yourself"
   #+END_SRC

   The result types =Step= and =Initial= now can represent =Error= for the
   driver to act accordingly.

   On extraction the driver needs to know the state of the parser. This is
   particularly useful to denote the success or a failed state when the input
   stream ends. This state is conveniently represented by =Either= (aliased to
   =Extract=).

   Extending for backtracking,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial Int s
         | Done Int b
         | Error String

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b
         | Error String

     -- | This is the result of @extract@
     type Extract b = Either String b

     -- | Data type representing the fold
     data Fold4 a b =
         forall s. Fold4 (s -> a -> Step s b) (Initial s b) (s -> Extract b)

     -- | The fold driver that runs the fold
     driver :: Fold4 a b -> [a] -> b
     driver = error "Try implementing this yourself"
   #+END_SRC

   This is a little tricky. We can represent backtracking in multiple ways.

   We can leave the logic of backtracking to the driver and communicate the
   amount to backtrack via the constructors.  Or, the types themselves can be
   designed to return the unused list of elements to the driver.

   We'll discuss the pros and cons of each method in another article. For now,
   we'll just let the driver handle backtracking.

   =Fold4= is essentially a parser or atleast the recipe of a parser. It is a
   blueprint that conveys the logic of parsing to driver.

   The entire parsing workflow would consist of the representation of the parser
   (=Fold4=) and the driver, reducing a stream of elements resulting in a parsed
   value.

** Where do you go from here

   Here are a few things you can do to understand the semantics of our design,
   1. Implement the =driver :: Fold4 a b -> [a] -> b=.
   2. Write a =sum :: Fold4 Int Int= parser.
   3. Write a =takeWhile :: (a -> Bool) -> Fold4 a b -> Fold4 a b= combinator.

   For the above tasks, make assumptions if the behaviour is not obvious. Try to
   choose the most natural behaviour. It's not an easy task so take your time
   and reason with the code.

   In a later article we'll make a bare-bones parsing library using this
   representation for parsers. That article will make things much clear and will
   act like a cheat sheet for implementation details.

* TODO A bare-bones parser library                                 :streamly:

* TODO Designing a parser combinator library                       :streamly:
  :PROPERTIES:
  :EXPORT_FILE_NAME: design-parser-comb-lib
  :EXPORT_HUGO_SECTION: blog
  :EXPORT_DATE: 2021-01-30
  :END:

  #+BEGIN_EXPORT html
  <style>
    .language-haskell {
      color: #fff!important;
    }
    .builtin {
      color: #fff!important;
    }
    .string {
      color: #fff!important;
    }
  </style>
  #+END_EXPORT

** Introduction

   In this article lets design and code a simple parser combinator library. The
   design that we'll come up with is a simplified version of direct style
   parsers in streamly.

** Overview

   We can all agree the universality of folds. They are very fundamental to
   functional programming. Parsers are nothing but glorified folds and just as
   fundamental. Having a good parsing library is essential for any functional
   ecosystem.

   =attoparsec= and =megaparsec= are the 2 most famous parsing libraries in
   Haskell. Parsers in both these libraries are represented in continuation
   passing style.

   In this article we'll define direct style parsers instead. They are easy to
   reason about and understand.

   You can read more about continuation passing & direct style
   here. https://github.com/composewell/streamly/pull/881/

** Design

   Parsers are nothing but an extension to folds with some more
   properties. Consider the type of a =foldl=.

   #+BEGIN_SRC haskell
     foldl :: (s -> a -> s) -> s -> [a] -> b
   #+END_SRC

   We can represent this as a data type,

   #+BEGIN_SRC haskell
     -- | Data type representing the fold
     data Fold a b =
         forall s. Fold (s -> a -> s) s (s -> b)

     -- | The fold driver that runs the fold
     driver :: Fold a b -> [a] -> b
     driver = undefined
   #+END_SRC

   For the ease of representation and combination we keep the state of the fold
   internal. Instead, we add a function =(s -> b)= to extract this internal
   state.

   The implementation of =driver= is left to the reader. Try implementing all
   the =undefined= functions for better understanding.

   Additional to the process of folding, the parser has these extra properties,
   - termination
   - backtracking
   - error handeling

   From the parser type, the parser driver should know whether to terminate,
   amount to backtrack and whether the parse is a success or a failure.

   Extending for termination,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial s
         | Done b

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b

     -- | Data type representing the fold
     data Fold2 a b =
         forall s. Fold2 (s -> a -> Step s b) (Initial s b) (s -> b)

     -- | The fold driver that runs the fold
     driver :: Fold2 a b -> [a] -> b
     driver = undefined
   #+END_SRC

   The reason we have different types for representing the result of step &
   initial is beause I preemptively know that these types are going to
   diverge. If you just want to create terminating folds you can use the same
   data type.

   =Fold2= represents terminating folds. The driver can terminate when it
   encounters =IDone= or =Done=. The implementation of the driver is left to the
   reader.

   Extending for error handeling,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial s
         | Done b
         | Error String

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b
         | IError String

     -- | This is the result of @extract@
     type Extract b = Either String b

     -- | Data type representing the fold
     data Fold3 a b =
         forall s. Fold3 (s -> a -> Step s b) (Initial s b) (s -> Extract b)

     -- | The fold driver that runs the fold
     driver :: Fold3 a b -> [a] -> b
     driver = undefined
   #+END_SRC

   The result types =Step= and =Initial= now can represent =Error= for the
   driver to act accordingly.

   On extraction the driver needs to know the state of the parser. This is
   particularly useful to denote the success or a failed state when the input
   stream ends. This state is conveniently represented by =Either= (aliased to
   =Extract=).

   Extending for backtracking,

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial Int s
         | Done Int b
         | Error String

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b
         | Error String

     -- | This is the result of @extract@
     type Extract b = Either String b

     -- | Data type representing the fold
     data Fold4 a b =
         forall s. Fold4 (s -> a -> Step s b) (Initial s b) (s -> Extract b)

     -- | The fold driver that runs the fold
     driver :: Fold4 a b -> [a] -> b
     driver = undefined
   #+END_SRC

   This is a little tricky. We can represent backtracking in multiple ways.

   We can leave the logic of backtracking to the driver and communicate the
   amount to backtrack via the constructors, which is what we are doing now.
   Or, the types themselves can be designed to return the unused list of
   elements to the driver.

   We'll discuss the pros and cons of each method in another article. For now,
   we'll just let the driver handle backtracking.

   =Fold4= is basically a parser. This is how a parser will look like in our
   experimental parser combinator library.

** Library

   Alright, let's start building our library. Our library will only contain one
   module named =Parser=.

   We'll start by adding some language extensions and creating a module header.

   #+BEGIN_SRC haskell
     {-# LANGUAGE ExistentialQuantification #-}

     module Parser where
   #+END_SRC

   =Fold4= will act as the base type for our library. Let's rename it to
   =Parser= and add it.

   #+BEGIN_SRC haskell
     -- | This is the result of the @step@ function
     data Step s b
         = Partial Int s
         | Done Int b
         | Error String

     -- | This is the initial value
     data Initial s b
         = IPartial s
         | IDone b
         | Error String

     -- | This is the result of @extract@
     type Extract b = Either String b

     -- | Data type representing the parser
     data Parser a b =
         forall s. Parser (s -> a -> Step s b) (Initial s b) (s -> Extract b)

     -- | The parser driver that runs the parser
     driver :: Parser a b -> [a] -> b
     driver = undefined
   #+END_SRC

   Every parser combinator library needs atleast one primitive parser. The only
   primitive parser in our library is =sum=.

   #+BEGIN_SRC haskell
     -- | A non-terminating non-failing parser that just adds elements
     sum :: Parser Int Int
     sum = Parser step initial extract

         where

         initial = IPartial 0
         step s a = Partial 0 (s + a)
         extract s = Right s
   #+END_SRC

   A parser combinator library is no good without basic combinators modifying
   the primitives. Our library contains two such combinators, namely,
   =takeWhile= and =takeEqualTo=.

   #+BEGIN_SRC haskell
     -- | A parser that takes while the predicate is true.
     -- Terminates: When predicate fails
     -- Fails: Never
     takeWhile :: (a -> Bool) -> Parser a b -> Parser a b
     takeWhile pred (Parser step initial extract) = Parser step1 initial1 extract1

         where

         initial1 = initial
         extract1 = extract

         step1 s a =
             if pred a
             then step s a
             else case extract s of
                      Left err -> Error err
                      Right b -> Done 1 b

     -- | A parser that takes exactly n elements.
     -- Terminates: After taking n elements
     -- Fails: When less than n elements are consumed
     takeEqualTo :: Int -> Parser a b -> Parser a b
     takeEqualTo n (Parser step initial extract) = Parser step1 initial1 extract1

         where

         initial1 =
             case initial of
                 IPartial s -> IPartial (0, s)
                 IDone b ->
                     if n == 0
                     then IDone b
                     else IError "takeGreaterThan: Took 0 elements"
                 IError err -> IError err

         extract1 (i, s) =
             if i == n
             then Right $ extract s
             else Left "takeGreaterThan: Took less than n elements"

         step1 (i, s) a =
             let i1 = i + 1
              in case step s a of
                     -- k elements are unconsumed and will be backtracked. We need to
                     -- update our state accordingly.
                     Partial k s -> Partial k (i1 - k, s)
                     Done k b ->
                         -- Since k elements will be backtracked, "i1 - k" is the
                         -- number of elements actually consumed.
                         if i1 - k == n
                         then Done k b
                         else Error "takeGreaterThan: Took less than n elements"
                     Error err -> Error err
   #+END_SRC

   And finally, the most important parser combinator combining multiple parsers,
   =splitWith=.

   #+BEGIN_SRC haskell
     data SplitWithState sl sr bl = SWLeft sl | SWRight bl sr

     -- | A parser that sequentially combines 2 parsers
     splitWith :: (b -> c -> d) -> Parser a b -> Parser a c -> Parser a d
     splitWith f (Parser stepL initialL extractL) (Parser stepR initialR extractR) =
         Parser step initial extract

         where

         initial =
             case initialL of
                 IPartial sl -> IPartial $ SWLeft sl
                 IDone bl ->
                     case initialR of
                         IPartial sr -> IPartial $ SWRight bl sr
                         IDone sb -> IDone $ f sl sb
                         IError err -> IError err
                 IError err -> IError err

         extract (SWLeft sl) =
             case extractL sl of
               Left err -> Left err
               Right bl ->
                   case initialR of
                     IPartial sr ->
                         case extractR sr of
                           Left err -> Left err
                           Right br -> Right $ f bl br
                     IDone br -> Right $ f bl br
                     IError err -> Left err

         step1 (SWLeft sl) a =
              case stepL sl a of
                     Partial n sl1 -> Partial n $ SWLeft sl1
                     Done n bl ->
                       case initialR of
                         IPartial sr -> Partial n $ SWRight bl sr
                         IDone br -> Done n $ f bl br
                         IError err -> Error err
                     Error err -> Error err

         step1 (SWRight bl sr) a =
              case stepR sr a of
                     Partial n sr1 -> Partial n $ SWRight bl sr1
                     Done n br -> Done n $ f bl br
                     Error err -> Error err
   #+END_SRC

   =splitWith= is written in a very idiomatic way to be direct and simple. One
   can cleverly abstract some common code either manually or with the use of
   type classes.

   This may be a lot to take in at once. Take your time and try reasoning with
   the code. Implement the driver, write down a simple parser using the
   combinators that we wrote and manually parse along.

   We can wrap up our library here. This is what a very primitive functional
   library of parsers would look like. The entire code togather is given below,

   #+BEGIN_SRC haskell
     {-# LANGUAGE ExistentialQuantification #-}

     module Parser where

     -- --------------------------------------------------------------------------
     -- Parser type
     -- --------------------------------------------------------------------------

     -- | This is the result of the @step@ function
     data Step s b = Partial Int s | Done Int b | Error String

     -- | This is the initial value
     data Initial s b = IPartial s | IDone b | Error String

     -- | Data type representing the parser
     data Parser a b = Parser (s -> a -> Step s b) (Initial s b) (s -> b)

     -- | The parser driver that runs the parser
     driver :: Parser a b -> [a] -> b
     driver = undefined

     -- --------------------------------------------------------------------------
     -- Primitive combinators
     -- --------------------------------------------------------------------------

     -- | A non-terminating non-failing parser that just adds elements
     sum :: Parser Int Int
     sum = Parser step initial extract

         where

         initial = IPartial 0
         step s a = Partial 0 (s + a)
         extract s = Right s

     -- --------------------------------------------------------------------------
     -- Modifying parsers
     -- --------------------------------------------------------------------------

     -- | A parser that takes while the predicate is true.
     -- Terminates: When predicate fails
     -- Fails: Never
     takeWhile :: (a -> Bool) -> Parser a b -> Parser a b
     takeWhile pred (Parser step initial extract) = Parser step1 initial1 extract1

         where

         initial1 = initial
         extract1 = extract

         step1 s a =
             if pred a
             then step s a
             else case extract s of
                      Left err -> Error err
                      Right b -> Done 1 b

     -- | A parser that takes exactly n elements.
     -- Terminates: After taking n elements
     -- Fails: When less than n elements are consumed
     takeEqualTo :: Int -> Parser a b -> Parser a b
     takeEqualTo n (Parser step initial extract) = Parser step1 initial1 extract1

         where

         initial1 =
             case initial of
                 IPartial s -> IPartial (0, s)
                 IDone b ->
                     if n == 0
                     then IDone b
                     else IError "takeGreaterThan: Took 0 elements"
                 IError err -> IError err

         extract1 (i, s) =
             if i == n
             then Right $ extract s
             else Left "takeGreaterThan: Took less than n elements"

         step1 (i, s) a =
             let i1 = i + 1
              in case step s a of
                     -- k elements are unconsumed and will be backtracked. We need to
                     -- update our state accordingly.
                     Partial k s -> Partial k (i1 - k, s)
                     Done k b ->
                         -- Since k elements will be backtracked, "i1 - k" is the
                         -- number of elements actually consumed.
                         if i1 - k == n
                         then Done k b
                         else Error "takeGreaterThan: Took less than n elements"
                     Error err -> Error err

     -- --------------------------------------------------------------------------
     -- Combining parsers
     -- --------------------------------------------------------------------------

     data SplitWithState sl sr bl = SWLeft sl | SWRight bl sr

     -- | A parser that sequentially combines 2 parsers
     splitWith :: (b -> c -> d) -> Parser a b -> Parser a c -> Parser a d
     splitWith f (Parser stepL initialL extractL) (Parser stepR initialR extractR) =
         Parser step initial extract

         where

         initial =
             case initialL of
                 IPartial sl -> IPartial $ SWLeft sl
                 IDone bl ->
                     case initialR of
                         IPartial sr -> IPartial $ SWRight bl sr
                         IDone sb -> IDone $ f sl sb
                         IError err -> IError err
                 IError err -> IError err

         extract (SWLeft sl) =
             case extractL sl of
               Left err -> Left err
               Right bl ->
                   case initialR of
                     IPartial sr ->
                         case extractR sr of
                           Left err -> Left err
                           Right br -> Right $ f bl br
                     IDone br -> Right $ f bl br
                     IError err -> Left err

         step1 (SWLeft sl) a =
              case stepL sl a of
                     Partial n sl1 -> Partial n $ SWLeft sl1
                     Done n bl ->
                       case initialR of
                         IPartial sr -> Partial n $ SWRight bl sr
                         IDone br -> Done n $ f bl br
                         IError err -> Error err
                     Error err -> Error err

         step1 (SWRight bl sr) a =
              case stepR sr a of
                     Partial n sr1 -> Partial n $ SWRight bl sr1
                     Done n br -> Done n $ f bl br
                     Error err -> Error err
   #+END_SRC

** Where do you go from here?

   The library that we've created is very small but has some really powerful
   combinators. One obvious improvement is to make the parsers effectful. We can
   do this by making the parser functions, namely, =step=, =initial=, and
   =extract= monadic.

   The parsers defined this way have an interesting property of fusion. When
   written properly, taking into the consideration the limits of the compiler,
   the parsers defined this way form tight loop with no intermediate
   constructors. The increases performance so much so that it can compete with
   carefully structured hand written C.

   What we've defined is very close to how direct style parsers are implemented
   in streamly. Improving this library will lead to the code defined in the
   =Parser-ish= modules of streamly. Once you're comfortable with this, feel
   free to contribute to parsers in streamly.

** Conclusion

   Streamly is ever-evolving and parsers are going to evolve with the library.
   A lot of improvements to parsers are planned and will be available in the
   near future.

   Although this guide might become obsolete within the next few releases of
   streamly, the ideas will remain the same. Quoting V, Ideas are bulletproof.

  #+BEGIN_EXPORT html
<script src="https://utteranc.es/client.js"
        repo="adithyaov/adithyaov.github.io"
        issue-term="title"
        label="utterance"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script>
  #+END_EXPORT

* Backup about parsers

  The design of parsers is inspired by the design of terminating folds. Extend
  terminating folds with backtracing and error handling and voila, you get a
  parser.

  A complete parsing workflow consists of the parser itself and driver that uses
  the parser on an input stream.

  Simply put, the parser is a higher level turing machine and the driver is
  something that runs this turing machine. The driver also manages the input
  tape for this turing machine.

*** Parser

  Instead of using a mathematical notation, lets describe this higher level
  turing machine in haskell.

  The parser in streamly is defined like so,

  #+BEGIN_SRC haskell
    data Step s b
        = Partial Int s
        | Continue Int s
        | Done Int b
        | Error String

    data Initial s b
        = IPartial s
        | IDone b
        | IError String

    type Extract b = Either String b

    data Parser m a b =
        forall s. Parser
                      (s -> a -> m (Step s b))
                      (m (Initial s b))
                      (s -> m (Extract b))
  #+END_SRC

  Unlike the turing maching the parser has a much more expressive transition
  (step) function =s -> a -> m (Step s b)=, a much more expressive initial state
  `(m (Initial s b))`

  The parser can either be in a state of uncertainity, a state of success, or a
  state of failure.

  Once the parser is in a state of success or a state of failure, the driver
  ends the process of parsing.





  - =s= is the intermediate state of the parser
  - =b= is the result of the parser on a successful parse
  -

  =a= is a finite, non-empty set of tape alphabet symbols (the input elements).
  =b= is the successful result of the



  Using the same symbols as above, =s= is the finite set of non-empty states. At
  any moment in time, =s= can be extracted to =b=




  The parser is a blueprint that the driver refers to. This blueprint should be
  composable and should be expressive enough to answer all the questions the
  driver asks.

  Parsing is a stateful computation and so this blueprint happens to also define
  a state. The driver does not need to know the state but should know how to
  interact with it.



  The parser should be designed to answer all the questions the driver can
  potentially ask. The driver can ask the following questions to the parser,

  1. Can I read the next element from the input stream? If not, should I
     consider this parse as a success or a failure?
  2. Given an input element, how do I fold it? Once folded, should I backtrack
     and continue parsing, or terminate? If I should terminate is it a success
     or a failed parse?
  3. At this current point in time, is the parse successful or unknown? An
     unknown state is a failed parse.



*** FAQ

    *Why does the driver need to ask 1? Why not just read the element and
    backtrack if it isn't required?*

    1. If the parser does not need to consume an element it would be an
       erroneous behavior to consume it.
    2. The input stream may never yield an input in which case the parser keeps
       waiting.

    *Why does the driver need to ask 2?*

    Well, that's the parser logic. A parser isn't much of a parser without 2.

    *Why does the driver need to ask 3? 2 already tells the driver whether to
    terminate successfully or fail?*

    The driver needs to know what to do when the input stream has no more
    elements and the parser has not terminated.

** Code correspondence

   The following is how the parser is defined in streamly,

   #+BEGIN_SRC haskell
     data Step s b
         = Partial Int s
         | Continue Int s
         | Done Int b
         | Error String

     data Initial s b
         = IPartial s
         | IDone b
         | IError String

     type Extract b = Either String b

     data Parser m a b =
         forall s. Parser
                       (s -> a -> m (Step s b))
                       (m (Initial s b))
                       (s -> m (Extract b))
   #+END_SRC

   The structure above is expressive enough to answer all the questions
   the driver can ask.

   =Initial=, along with wrapping the internal state of the parser, instructs
   the driver whether it should read the next element or terminate. =IDone=
   indicates successful termination whereas =IError= indicates a failed one.

   The step function tells the driver how the element should be folded with a
   previous state. The return type of the step function =Step=, along with
   encapsulating the new state, instructs the parser whether to backtrack and
   continue or terminate. =Done= and =Error= correspond to successful and failed
   termination states.

   =Extract= expresses whether the internal state at the current moment
   indicates a successful or a failed parse, conveniently encoded by =Either=.

** Driver workflow

   At this point, the workflow of the driver is rather straight
   forward. Regardless of how a driver is implemented the driver does the
   following,

   #+BEGIN_SRC plantuml :file ./static/driver-workflow.png
State1: Read the element?
State2: Element is available?
State3: Fold the element
State4: Terminate or backtrack?
State5: Backtrack
State6: Check termination state
State7: End parsing as Success
State8: End parsing as Failure

State1 --> State2 : Yes
State1 --> State6 : No

State2 --> State3 : Yes
State2 --> State6 : No

State3 --> State4

State4 --> State6 : Terminate
State4 --> State5 : Backtrack

State5 --> State1

State6 --> State7 : Success
State6 --> State8 : Failure
   #+END_SRC

   #+RESULTS:
   [[file:./static/driver-workflow.png]]


** Closing statements

   Streamly is ever-evolving and parsers are going to evolve with the
   library. There are a lot of plans to make parsers more expressive and
   efficient. Although this guide might become obsolete within the next few
   releases of streamly, the ideas will remain the same. Quoting V, Ideas are
   bulletproof.


* TODO Quadratic complexity of direct style composition


* TODO Partial vs Continue

  Having =Partial= gives the parser more expressivity. =Partial= puts the parser
  in a success state. Once we reach =Partial= we never go back to =Continue=. We
  also drop the additional buffer when =Partial= is reached. One can replace
  =Partial= with =Continue= and the code will still be correct but less
  performant.

* TODO Buffering in parsers

  Without much digression, let me state that buffering of the input stream for
  backtracking is currently handeled by the driver. We could potentially move
  the implementation of buffering to the parser itself but there are [pros and
  cons for either case].


* TODO Kontinuation style parsing

* TODO Lazy functinal state threads

* TODO More generality leads to lesser performance

* TODO concatMap vs inject-isq

  Consider the all powerful =concatMap=. It is probably the most general operation
  w.r.t any type that streamly has.

  In most cases such generality might not be required which is evident in the
  case of =Unfold=. This intermediate generality was possible because the
  representation contained =inject=.

  Chaining =Unfold= with =concat= turns out to be very efficient as the compiler
  has the required information at compile time for optimization.

  It should be possible to do the same for =Fold= and =Parser=.

   #+BEGIN_SRC haskell
     data Fold m i a b =
         -- | @Fold @ @ step @ @ inject @ @ extract@
         forall s. Fold (s -> a -> m (Step s b)) (i -> m (Step s b)) (s -> m b)

     split :: Fold m i a j -> Fold m j a b -> Fold m i a b
     split = undefined
   #+END_SRC

   Something like this can be used in most cases where one might want to use
   =concatMap=-ish combinator.

   If you consider parsing a packet of some protocol with variable length
   fields, this approach would be significantly more performant than using
   =concatMap=.

   I haven't given too much thought to it so I might have missed something. Did
   you try something like this before?

   This came to mind when I was thinking about parsing the header for streams in
   =streamly-lz4=, with the broader topic being, expressivity vs performance.

* TODO Blogging: The source of truth                                  :emacs:

* Awesome git

  - [ ] https://github.com/hercules-team/augeas
  - [ ] https://github.com/composewell/streamly (biased)

* Read/Watch-List

  This page containes is a list of interesting videos and papers that I plan to
  (re-)visit.

  - [X] [[https://www.youtube.com/watch?v=F_Riqjdh2oM][Quantum Computing for Computer Scientists]]
  - [X] [[https://wiki.haskell.org/Evaluation_order_and_state_tokens][Evaluation order and state tokens]]
  - [ ] [[https://arxiv.org/pdf/1611.09471.pdf][Learn Quantum Mechanics with Haskell]]
  - [ ] [[https://eprint.iacr.org/2015/007.pdf][Balloon: A Forward-Secure Append-OnlyPersistent Authenticated Data Structure]]
  - [ ] [[http://www.ats-lang.org/MYDATA/Xanadu-lics00.pdf][Imperative Programming with Dependent Types]]

* Gotchas

  - =case= is lazy by default in Haskell
    - The use of constructor makes =case= strict. We have to evaluate the
      scrutenee to match
  - bang in =let= is not a bang pattern

* Local variables

# Local Variables:
# eval: (org-babel-do-load-languages 'org-babel-load-languages '((shell . t)))
# eval: (setq org-confirm-babel-evaluate nil)
# End:
